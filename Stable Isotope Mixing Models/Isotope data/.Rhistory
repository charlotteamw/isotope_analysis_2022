group = 7,
title = "simmr output Golden Shiner Liver in May"
)
plot(ope_simmr_out,
type = "boxplot",
group = 42,
title = "simmr output SMBMuscle in May"
)
plot(ope_simmr_out,
type = "boxplot",
group = 40,
title = "simmr output SMB liver in May"
)
library(simmr)
library(readxl)
# Specify the file path to your Excel file
path <- "C:/Users/charl/Documents/Costello_Opeongo_DataAnalysis/Isotope Analysis 2022 OpeCostello/Stable Isotope Mixing Models/Isotope Data/ope_costello_2022.xlsx"
# Read the Excel file
ope_costello <- lapply(excel_sheets(path), read_excel, path = path)
targets <- ope_costello[[1]]
sources <-ope_costello[[2]]
TEFs <- ope_costello[[3]]
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
View(sources)
View(ope_costello)
View(TEFs)
View(ope_costello)
View(sources)
View(targets)
View(sources)
targets <- as.matrix(ope_costello[[1]])
sources <-as.matrix(ope_costello[[2]])
TEFs <- as.matrix(ope_costello[[3]])
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
targets <- as.matrix.data.frame(ope_costello[[1]])
sources <-as.matrix.data.frame(ope_costello[[2]])
TEFs <- as.matrix.data.frame(ope_costello[[3]])
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
install.packages("simmr")
library(simmr)
# Specify the file path to your Excel file
path <- "C:/Users/charl/Documents/Costello_Opeongo_DataAnalysis/Isotope Analysis 2022 OpeCostello/Stable Isotope Mixing Models/Isotope Data/ope_costello_2022.xlsx"
# Read the Excel file
ope_costello <- lapply(excel_sheets(path), read_excel, path = path)
targets <- as.matrix.data.frame(ope_costello[[1]])
sources <-as.matrix.data.frame(ope_costello[[2]])
TEFs <- as.matrix.data.frame(ope_costello[[3]])
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
# Read the Excel file
ope_costello <- lapply(excel_sheets(path), read_excel, path = path)
targets <- as.matrix.data.frame(ope_costello[[1]])
library(readxl)
# Read the Excel file
ope_costello <- lapply(excel_sheets(path), read_excel, path = path)
targets <- as.matrix.data.frame(ope_costello[[1]])
sources <-as.matrix.data.frame(ope_costello[[2]])
TEFs <- as.matrix.data.frame(ope_costello[[3]])
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
targets <- ope_costello[[1]]
sources <- ope_costello[[2]]
TEFs <- ope_costello[[3]]
ope_simmr <- simmr_load(
mixtures = targets[, 1:3],
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
ope_simmr <- simmr_load(
mixtures = targets[, c(1,2,3)],
source_names = sources$Sources,
source_means = sources[, c(2,3,4)],
source_sds = sources[, c(5,6,7)],
correction_means = TEFs[, c(2,3,4)],
correction_sds = TEFs[, c(5,6,7)],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
View(targets)
print(targets)
targets_matrix <- as.matrix(targets[, 1:3])
ope_simmr <- simmr_load(
mixtures = targets_matrix,
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location,  targets$organism,  targets$tissue,  targets$month))
)
targets <- ope_costello[[1]]
sources <- ope_costello[[2]]
TEFs <- ope_costello[[3]]
# Convert targets to a matrix
targets_matrix <- as.matrix(targets[, 1:3])
ope_simmr <- simmr_load(
mixtures = targets_matrix,
source_names = sources$Sources,
source_means = sources[, 2:4],
source_sds = sources[, 5:7],
correction_means = TEFs[, 2:4],
correction_sds = TEFs[, 5:7],
group = as.factor(paste("location_organism_tissue_month", targets$location, targets$organism, targets$tissue, targets$month))
)
setwd("C:/Users/charl/Documents")
helms_dat<- read.csv("Helms et al. data.csv", header = TRUE)
helms_dat<- read.csv("Helms et al. data.csv", header = TRUE)
View(helms_dat)
library(tidyverse)
View(helms_dat)
# Perform the ANOVA
helms_anova <- aov(FCL ~ Treatment, data = helms_data)
# Perform the ANOVA
helms_anova <- aov(FCL ~ Treatment, data = helms_dat)
# View the summary of the ANOVA results
summary(result_anova)
# View the summary of the ANOVA results
summary(helms_anova)
helms_dat<- read.csv("Helms et al. data.csv", header = TRUE)
library(tidyverse)
# Group "Switchgrass" and "Prairie" together as "Perennials"
helms_dat$Treatment <- ifelse(helms_dat$Treatment %in% c("Switchgrass", "Prairie"), "Perennials", helms_dat$Treatment)
# Perform the ANOVA
helms_anova <- aov(FCL ~ Treatment, data = helms_dat)
# View the summary of the ANOVA results
summary(helms_anova)
View(helms_anova)
View(helms_dat)
View(helms_anova)
View(helms_dat)
setwd("C:/Users/charl/Documents")
# Load required libraries
library(tm)
library(wordcloud2)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
View(data)
# Extract keywords as a character vector
keywords <- unlist(strsplit(as.character(data$Keywords), ", "))
keywords<- as.data.frame(keywords)
View(keywords)
library(tidyverse)
# Assuming your data frame is named 'df'
words <- keywords_text %>%
group_by(keywords_text) %>%
summarize(count= n()) %>%
ungroup()
# Assuming your data frame is named 'df'
words <- keywords %>%
group_by(keywords) %>%
summarize(count= n()) %>%
ungroup()
View(words)
install.packages("stringr")
# Load required libraries
library(tm)
library(wordcloud2)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Extract keywords as a character vector
keywords <- unlist(strsplit(as.character(data$Keywords), ", "))
# Convert keywords to lowercase
keywords <- tolower(keywords)
# Remove plural forms using stringr package
library(stringr)
keywords <- str_replace(keywords, "s$", "")
# Convert the modified keywords back to a data frame
keywords <- as.data.frame(keywords)
keywords$keywords <- ifelse(keywords$keywords == "stable isotope analysi", "stable isotope", keywords$keywords)
library(tidyverse)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
slice_max(order_by = count, n = 50)    # Keep the top 50 keywords based on count
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
View(keywords)
View(words)
View(words)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)    # Keep the top 50 keywords based on count
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Extract keywords as a character vector
keywords <- unlist(strsplit(as.character(data$Keywords), ", "))
# Convert keywords to lowercase
keywords <- tolower(keywords)
# Remove plural forms using stringr package
library(stringr)
keywords <- str_replace(keywords, "s$", "")
# Convert the modified keywords back to a data frame
keywords <- as.data.frame(keywords)
library(tidyverse)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)    # Keep the top 50 keywords based on count
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
keywords$keywords <- ifelse(keywords$keywords == "stable isotope analysi", "stable isotope", keywords$keywords)
library(tidyverse)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)    # Keep the top 50 keywords based on count
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)%>%
arrange(desc(count))
# Keep the top 50 keywords based on count
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
View(words)
colnames(words) <- c("name", "freq")
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
colnames(words) <- c("word", "freq")
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud2(words, size = 1, backgroundColor = "white")
# Create the word cloud using wordcloud2
wordcloud2(data = words)
write.csv(words, "keywords_2023_struct_shifts.csv")
library(wordcloud2)
write.csv(words, "keywords_2023_struct_shifts.csv")
write.csv(words, "keywords_2023_struct_shifts.csv")
library(wordcloud)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Extract keywords as a character vector
keywords <- unlist(strsplit(as.character(data$Keywords), ", "))
# Convert keywords to lowercase
keywords <- tolower(keywords)
# Remove plural forms using stringr package
library(stringr)
keywords <- str_replace(keywords, "s$", "")
# Convert the modified keywords back to a data frame
keywords <- as.data.frame(keywords)
keywords$keywords <- ifelse(keywords$keywords == "stable isotope analysi", "stable isotope", keywords$keywords)
library(tidyverse)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)
colnames(words) <- c("word", "freq")
# View the updated data frame
print(words)
# Create the word cloud using wordcloud2
wordcloud(data = words)
View(words)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 51)
colnames(words) <- c("word", "freq")
# View the updated data frame
print(words)
write.csv(words, "keywords_2023_struct_shifts.csv")
# Create the word cloud using wordcloud2
wordcloud(data = words)
# Create the word cloud using wordcloud2
wordcloud( words)
library(wordcloud2)
# Load the data from CSV
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
# Extract keywords as a character vector
keywords <- unlist(strsplit(as.character(data$Keywords), ", "))
# Convert keywords to lowercase
keywords <- tolower(keywords)
# Remove plural forms using stringr package
library(stringr)
keywords <- str_replace(keywords, "s$", "")
# Convert the modified keywords back to a data frame
keywords <- as.data.frame(keywords)
keywords$keywords <- ifelse(keywords$keywords == "stable isotope analysi", "stable isotope", keywords$keywords)
library(tidyverse)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 51)
colnames(words) <- c("word", "freq")
# View the updated data frame
print(words)
write.csv(words, "keywords_2023_struct_shifts.csv")
# Create the word cloud using wordcloud2
wordcloud2
# Create the word cloud using wordcloud2
wordcloud2(data=words)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count))
colnames(words) <- c("word", "freq")
# View the updated data frame
print(words)
write.csv(words, "keywords_2023_struct_shifts.csv")
# Create the word cloud using wordcloud2
wordcloud2(data=words)
View(words)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size =.5)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 50)
colnames(words) <- c("word", "freq")
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.1)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.5
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.5)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.5)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.2)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 1)
colnames(words) <- c("word", "freq")
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.2)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.5)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 10)
colnames(words) <- c("word", "freq")
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.5)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.1)
write.csv(words,file = "wordcloud_data.csv", row.names = FALSE)
write.csv(words,file = "wordcloud_data.csv", row.names = FALSE)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 100)
colnames(words) <- c("word", "freq")
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.1)
write.csv(words,file = "wordcloud_data.csv", row.names = FALSE)
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.1)
write.csv(words,file = "wordcloud_data.csv", row.names = FALSE)
data <- read.csv("wordcloud_keywords.csv", header = TRUE)
View(data)
data <- read.csv("wordcloud_data.csv", header = TRUE)
View(data)
# Sort data by frequency (descending order)
word_freq_data <- data[order(-data$freq), ]
View(word_freq_data)
View(data)
View(word_freq_data)
# Define colors for the boxes
my_colors <- rainbow(nrow(data))
# Create the plot
ggplot(data, aes(x = word, y = freq, fill = word)) +
geom_bar(stat = "identity") +
scale_fill_manual(values = my_colors) +
coord_flip() +
labs(title = "Words Represented as a Grid of Boxes",
x = "Words",
y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guides(fill = FALSE)
install.packages("ggforce")
ggplot(data, aes(x = word, y = freq)) +
geom_tile(aes(width = 1, height = freq), fill = "lightblue", color = "black") +
geom_text(aes(label = word), vjust = 0.5, hjust = 0.5, size = 3) +
coord_flip() +
labs(title = "Words Represented as a Puzzle Grid of Boxes",
x = "Words",
y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.title.x = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.x = element_line(color = "gray", linetype = "dashed"),
panel.grid.minor.x = element_blank()) +
guides(fill = FALSE)
words <- keywords %>%
group_by(keywords) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(count = as.numeric(count)) %>%  # Convert count to numeric
arrange(desc(count)) %>%              # Sort in descending order of count
slice_max(order_by = count, n = 30)
colnames(words) <- c("word", "freq")
# Create the word cloud using wordcloud2
wordcloud2(data=words, size = 0.1)
# Load required libraries
library(tm)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
df_isotopes <- read.csv("..//Isotope data/all_data_aly_char.csv", header = T)
df_isotopes <- read.csv("..//Isotope data/2022_isotopes_ERICA_DATA.csv", header = T)
df_isotopes <- read.csv("..//Isotope data/2022_isotopes_ERICA_DATA", header = T)
df_isotopes <- read.csv("..//Isotope data/2022_isotopes_ERICA_DATA.csv", header = T)
setwd("C:/Users/charl/Documents/Costello_Opeongo_DataAnalysis/Isotope Analysis 2022 OpeCostello/Stable Isotope Mixing Models/Isotope data")
df_isotopes <- read.csv("..//Isotope data/2022_isotopes_ERICA_DATA.csv", header = T)
View(df_isotopes)
View(df_isotopes)
